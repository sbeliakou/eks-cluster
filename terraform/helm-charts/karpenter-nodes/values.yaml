nodePoolName: default
nodeClassName: default

eksNodeGroupIAMRole: ""
clusterName: ""

userData: ""
detailedMonitoring: false

# Resource limits constrain the total size of the cluster.
# Limits prevent Karpenter from creating new instances once the limit is exceeded.
limits:
  cpu: "100"
  memory: 10Gi

# Disruption section which describes the ways in which Karpenter can disrupt and replace Nodes
# Configuration in this section constrains how aggressive Karpenter can be with performing operations
# like rolling Nodes due to them hitting their maximum lifetime (expiry) or scaling down nodes to reduce cluster cost
disruption:
    # Describes which types of Nodes Karpenter should consider for consolidation
    # If using 'WhenUnderutilized', Karpenter will consider all nodes for consolidation and attempt to remove or replace Nodes when it discovers that the Node is underutilized and could be changed to reduce cost
    # If using `WhenEmpty`, Karpenter will only consider nodes for consolidation that contain no workload pods
    consolidationPolicy: WhenUnderutilized
    
    # The amount of time Karpenter should wait after discovering a consolidation decision
    # This value can currently only be set when the consolidationPolicy is 'WhenEmpty'
    # You can choose to disable consolidation entirely by setting the string value 'Never' here
    consolidateAfter: 30s
    
    # The amount of time a Node can live on the cluster before being removed
    # Avoiding long-running Nodes helps to reduce security vulnerabilities as well as to reduce the chance of issues that can plague Nodes with long uptimes such as file fragmentation or memory leaks from system processes
    # You can choose to disable expiration entirely by setting the string value 'Never' here
    expireAfter: 720h

# Requirements that constrain the parameters of provisioned nodes.
# These requirements are combined with pod.spec.topologySpreadConstraints, pod.spec.affinity.nodeAffinity, pod.spec.affinity.podAffinity, and pod.spec.nodeSelector rules.
# Operators { In, NotIn, Exists, DoesNotExist, Gt, and Lt } are supported.
# https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#operators
nodepool_requirements:
- key: "kubernetes.io/arch"
  operator: In
  values: ["amd64"]
- key: "kubernetes.io/os"
  operator: In
  values: ["linux"]
- key: "karpenter.sh/capacity-type"
  operator: In
  values: ["spot"]
- key: "karpenter.k8s.aws/instance-category"
  operator: In
  values: ["c", "m", "r"]
- key: "karpenter.k8s.aws/instance-cpu"
  operator: In
  values: ["4", "8", "16", "32"]
- key: "karpenter.k8s.aws/instance-generation"
  operator: Gt
  values: ["2"]

# Karpenter provides the ability to specify a few additional Kubelet args.
# These are all optional and provide support for additional customization and use cases.
kubelet: {}
# kubelet:
#   clusterDNS: ["10.0.1.100", "10.0.1.100"]
#   containerRuntime: containerd
#   systemReserved:
#     cpu: 100m
#     memory: 100Mi
#     ephemeralStorage: 1Gi
#   kubeReserved:
#     cpu: 200m
#     memory: 100Mi
#     ephemeralStorage: 3Gi
#   evictionHard:
#     memoryAvailable: 5%
#     nodefsAvailable: 10%
#     nodefsInodesFree: 10%
#   evictionSoft:
#     memoryAvailable: 500Mi
#     nodefsAvailable: 15%
#     nodefsInodesFree: 15%
#   evictionSoftGracePeriod:
#     memoryAvailable: 1m
#     nodefsAvailable: 1m30s
#     nodefsInodesFree: 2m
#   evictionMaxPodGracePeriod: 60
#   imageGCHighThresholdPercent: 85
#   imageGCLowThresholdPercent: 80
#   cpuCFSQuota: true
#   podsPerCore: 2
#   maxPods: 20